# tcia-lung1-seg-class

## ğŸ“Œ Project Overview

Endâ€‘toâ€‘end healthcare ML imaging pipeline using TCIA NSCLCâ€‘Radiomics lung cancer CT data.

### Workflow

- **Segmentation** â†’ nnUâ€‘Net trained from scratch
- **Classification** â†’ Transformer fineâ€‘tuned with pretrained weights
- **Integration** â†’ Epic Sandbox APIs (FHIR) for workflow alignment
- **Deployment** â†’ Azure ML Studio with complianceâ€‘ready environment

## ğŸ§© Key Features

- ğŸ”¬ **Medical Imaging**: DICOM preprocessing, resampling, normalization
- ğŸ§  **Deep Learning**: nnUâ€‘Net segmentation + transformer classification
- ğŸ“Š **Evaluation**: ROC, confusion matrices, reproducible metrics
- â˜ï¸ **Cloud Ready**: Azure ML Studio deployment artifacts
- ğŸ¥ **Workflow Integration**: Epic Sandbox API adapters (FHIR standard)
- ğŸ”’ **Compliance**: HIPAA/FDA notes, PHI handling policy documented

## ğŸ“‚ Repository Structure

```txt
tcia-lung1-seg-class/
â”œâ”€â”€ src/               # Core Python modules
â”œâ”€â”€ configs/           # YAML configs for reproducibility
â”œâ”€â”€ notebooks/         # Exploration & visualization
â”œâ”€â”€ tests/             # Unit/integration tests
â”œâ”€â”€ docs/              # Compliance + workflow documentation
â”œâ”€â”€ scripts/           # CLI entry points
â”œâ”€â”€ cloud/             # Azure ML + Epic Sandbox integration
â”œâ”€â”€ environment.yml    # Conda environment (heavy ML stack)
â”œâ”€â”€ requirements.txt   # Pip extras (dev tools, FHIR client)
â””â”€â”€ README.md          # Project overview
```

## âš™ï¸ Environment Setup

Local + cloud environments are unified for reproducibility.

### Create environment

```bash
conda env create -f environment.yml
conda activate tcia-lung1-seg-class
```

### Verify installation

```bash
python -c "import torch, monai, nibabel, simpleitk; print('Environment OK')"
```

For details, see `docs/env_setup.md`.

## ğŸš€ Usage

### Preprocessing

```bash
python scripts/run_preprocessing.py --config configs/preprocessing.yaml
```

### Segmentation

```bash
python scripts/train_segmentation.py --config configs/nnunet_train.yaml
```

### Classification

```bash
python scripts/train_classification.py --config configs/transformer_class.yaml
```

### Deployment

```bash
python scripts/deploy_cloud.py --config configs/deploy.yaml
```

## ğŸ”’ Compliance

- **No PHI**: Only TCIA NSCLCâ€‘Radiomics (public dataset) used
- **Audit Trail**: Configs + logs maintained under version control
- **Secrets**: Epic Sandbox + Azure credentials stored in `.env` files
- **Documentation**: See `docs/compliance.md`

## ğŸ“Š Results

- Segmentation Dice scores (nnUâ€‘Net)
- Classification ROC curves (transformer)
- Cloud deployment screenshots (Azure ML Studio)

## ğŸ¤ Contributions

Pull requests welcome. Please review compliance guidelines before submitting.

## ğŸ“œ License

Explicit license included for medical/clinical reproducibility.
